{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQzJIgrxIcJ2",
        "outputId": "5b01f84f-ca5e-4e17-8a86-551ddc30259c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Unzipping data... this takes about 30-60 seconds...\n",
            "Data ready!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# 1. Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Copy and Unzip\n",
        "zip_path = '/content/drive/MyDrive/Classes/AML/asos_images_raw.zip'\n",
        "extract_path = '/content/dataset'\n",
        "\n",
        "print(\"Unzipping data... this takes about 30-60 seconds...\")\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Data ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<audio src=\"https://raw.githubusercontent.com/anars/blank-audio/master/10-minutes-of-silence.mp3\" autoplay loop controls />"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "p4NQ-8T8VJnL",
        "outputId": "33b97721-08ba-4fbc-cee1-4227c85722bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<audio src=\"https://raw.githubusercontent.com/anars/blank-audio/master/10-minutes-of-silence.mp3\" autoplay loop controls />\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import torch.amp\n",
        "import concurrent.futures\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# --- 1. WINNING CONFIGURATION ---\n",
        "# Based on hyperparameter tuning\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = 0.0012  # Winner\n",
        "HIDDEN_DIM = 1024       # Winner\n",
        "NUM_LAYERS = 2          # Winner\n",
        "DROPOUT_RATE = 0.3      # Winner\n",
        "WEIGHT_DECAY = 1e-4\n",
        "\n",
        "# Training Duration (Longer for production)\n",
        "EPOCHS_STAGE_1 = 20\n",
        "EPOCHS_STAGE_2 = 20\n",
        "LR_FINE_TUNE = 1e-5     # Low LR for unfreezing\n",
        "\n",
        "DEVICE = torch.device(\"cuda\")\n",
        "SAVE_DIR = '/content/drive/MyDrive/Classes/AML'\n",
        "IMG_DIR = '/content/dataset/asos_images_raw'\n",
        "CLEAN_CSV_PATH = '/content/asos_final_clean.csv'"
      ],
      "metadata": {
        "id": "idM555AnMTrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. DATA LOADERS ---\n",
        "class ASOSMemDataset(Dataset):\n",
        "    def __init__(self, dataframe, img_dir):\n",
        "        self.metadata = dataframe.copy().reset_index(drop=True)\n",
        "        self.img_dir = img_dir\n",
        "        self.images = [None] * len(self.metadata)\n",
        "        self.prices = [None] * len(self.metadata)\n",
        "\n",
        "        print(f\"Caching {len(self.metadata)} images...\")\n",
        "        def load_single_image(idx):\n",
        "            try:\n",
        "                row = self.metadata.iloc[idx]\n",
        "                sku = str(int(row['sku']))\n",
        "                img_path = os.path.join(self.img_dir, f\"{sku}.jpg\")\n",
        "                with Image.open(img_path) as img:\n",
        "                    return idx, img.convert('RGB').resize((224, 224)), float(row['price'])\n",
        "            except:\n",
        "                return idx, None, None\n",
        "\n",
        "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "            futures = [executor.submit(load_single_image, i) for i in range(len(self.metadata))]\n",
        "            for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures), unit=\"img\"):\n",
        "                idx, img, price = future.result()\n",
        "                if img is not None:\n",
        "                    self.images[idx] = img\n",
        "                    self.prices[idx] = np.log1p(price)\n",
        "\n",
        "        self.images = [img for img in self.images if img is not None]\n",
        "        self.prices = [p for p in self.prices if p is not None]\n",
        "\n",
        "    def __len__(self): return len(self.images)\n",
        "    def __getitem__(self, idx): return self.images[idx], torch.tensor(self.prices[idx], dtype=torch.float32)"
      ],
      "metadata": {
        "id": "4oVoOxDxMS_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmYJIiyBUjiQ",
        "outputId": "b2dddccf-7c81-4ef9-9e52-95e3258544f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caching 23976 images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23976/23976 [21:53<00:00, 18.25img/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caching 2997 images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2997/2997 [02:41<00:00, 18.57img/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caching 2998 images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2998/2998 [02:42<00:00, 18.43img/s]\n"
          ]
        }
      ],
      "source": [
        "# Transforms\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "class TransformedDataset(Dataset):\n",
        "    def __init__(self, base_dataset, transform):\n",
        "        self.base = base_dataset\n",
        "        self.transform = transform\n",
        "    def __len__(self): return len(self.base)\n",
        "    def __getitem__(self, idx):\n",
        "        img, price = self.base[idx]\n",
        "        return self.transform(img), price\n",
        "\n",
        "# Split Data\n",
        "df = pd.read_csv(CLEAN_CSV_PATH, on_bad_lines='skip', engine='python')\n",
        "df = df[df['price'] < 1000]\n",
        "train_val_df, test_df = train_test_split(df, test_size=0.10, random_state=42)\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=0.1111, random_state=42)\n",
        "\n",
        "raw_train = ASOSMemDataset(train_df, IMG_DIR)\n",
        "raw_val = ASOSMemDataset(val_df, IMG_DIR)\n",
        "raw_test = ASOSMemDataset(test_df, IMG_DIR)\n",
        "\n",
        "train_loader = DataLoader(TransformedDataset(raw_train, train_transforms), batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "val_loader = DataLoader(TransformedDataset(raw_val, val_transforms), batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "test_loader = DataLoader(TransformedDataset(raw_test, val_transforms), batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "    model = models.convnext_tiny(weights='DEFAULT')\n",
        "    for param in model.parameters(): param.requires_grad = False\n",
        "\n",
        "    input_dim = model.classifier[2].in_features\n",
        "    layers = []\n",
        "    current_in = input_dim\n",
        "\n",
        "    # Funnel Logic (From Alibaba / Stanford Ideas)\n",
        "    for i in range(NUM_LAYERS):\n",
        "        out_dim = int(HIDDEN_DIM / (2**i)) # 1024 -> 512\n",
        "        layers.append(nn.Linear(current_in, out_dim))\n",
        "        layers.append(nn.BatchNorm1d(out_dim))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.Dropout(DROPOUT_RATE))\n",
        "        current_in = out_dim\n",
        "\n",
        "    layers.append(nn.Linear(current_in, 1))\n",
        "    model.classifier[2] = nn.Sequential(*layers)\n",
        "    return model.to(DEVICE)\n",
        "\n",
        "model = build_model()\n",
        "criterion = nn.MSELoss()\n",
        "scaler = torch.amp.GradScaler('cuda')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAMN1eGn8epM",
        "outputId": "3f963abb-a708-4f4b-894a-42b7e2a59dd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/convnext_tiny-983f1562.pth\" to /root/.cache/torch/hub/checkpoints/convnext_tiny-983f1562.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109M/109M [00:00<00:00, 237MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STAGE 1: HEAD TRAINING ---\n",
        "print(f\"\\n=== STAGE 1: Training Head ({EPOCHS_STAGE_1} Epochs) ===\")\n",
        "optimizer = optim.AdamW(model.classifier.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
        "\n",
        "for epoch in range(EPOCHS_STAGE_1):\n",
        "    model.train()\n",
        "    loop = tqdm(train_loader, desc=f\"S1 Ep {epoch+1}\")\n",
        "    for img, price in loop:\n",
        "        img, price = img.to(DEVICE), price.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            out = model(img)\n",
        "            loss = criterion(out.squeeze(), price)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for img, price in val_loader:\n",
        "            img, price = img.to(DEVICE), price.to(DEVICE)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                out = model(img)\n",
        "                val_loss += criterion(out.squeeze(), price).item()\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    print(f\"  >>> Val Loss: {val_loss:.4f}\")\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "# Save Stage 1 Checkpoint\n",
        "torch.save(model.state_dict(), os.path.join(SAVE_DIR, 'asos_stage1_done.pth'))\n",
        "\n",
        "# --- STAGE 2: FINE-TUNING ---\n",
        "print(f\"\\n=== STAGE 2: Unfreezing Backbone ({EPOCHS_STAGE_2} Epochs) ===\")\n",
        "# Unfreeze last 2 blocks of ConvNeXt\n",
        "for param in model.features[6].parameters(): param.requires_grad = True\n",
        "for param in model.features[7].parameters(): param.requires_grad = True\n",
        "\n",
        "# Low LR for stability\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LR_FINE_TUNE, weight_decay=WEIGHT_DECAY)\n",
        "best_mae = float('inf')\n",
        "\n",
        "for epoch in range(EPOCHS_STAGE_2):\n",
        "    model.train()\n",
        "    loop = tqdm(train_loader, desc=f\"S2 Ep {epoch+1}\")\n",
        "    for img, price in loop:\n",
        "        img, price = img.to(DEVICE), price.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            out = model(img)\n",
        "            loss = criterion(out.squeeze(), price)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    # Full Validation (Real $)\n",
        "    model.eval()\n",
        "    val_preds, val_targets = [], []\n",
        "    with torch.no_grad():\n",
        "        for img, price in val_loader:\n",
        "            img, price = img.to(DEVICE), price.to(DEVICE)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                out = model(img)\n",
        "            val_preds.extend(out.squeeze().float().cpu().numpy())\n",
        "            val_targets.extend(price.cpu().numpy())\n",
        "\n",
        "    real_preds = np.expm1(np.clip(val_preds, 0, 10))\n",
        "    real_targets = np.expm1(val_targets)\n",
        "    val_mae = np.mean(np.abs(real_preds - real_targets))\n",
        "\n",
        "    print(f\"  >>> Val MAE: ${val_mae:.2f}\")\n",
        "\n",
        "    if val_mae < best_mae:\n",
        "        best_mae = val_mae\n",
        "        torch.save(model.state_dict(), os.path.join(SAVE_DIR, 'asos_final_best.pth'))\n",
        "        print(\"  >>> New Best Model Saved!\")\n",
        "\n",
        "print(\"Training Complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqTSOHKmdJGj",
        "outputId": "56085074-8f4b-48c1-8553-3c64a7ca67b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== STAGE 1: Training Head (20 Epochs) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S1 Ep 1: 100%|██████████| 188/188 [01:19<00:00,  2.37it/s, loss=0.61]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val Loss: 0.3233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S1 Ep 2: 100%|██████████| 188/188 [01:05<00:00,  2.87it/s, loss=0.349]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val Loss: 0.3198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S1 Ep 3: 100%|██████████| 188/188 [01:05<00:00,  2.85it/s, loss=0.213]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val Loss: 0.2691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S1 Ep 4: 100%|██████████| 188/188 [01:05<00:00,  2.88it/s, loss=0.261]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val Loss: 0.2748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S1 Ep 5: 100%|██████████| 188/188 [01:05<00:00,  2.87it/s, loss=0.227]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val Loss: 0.2894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S1 Ep 6: 100%|██████████| 188/188 [01:05<00:00,  2.88it/s, loss=0.586]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val Loss: 0.2999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S1 Ep 7: 100%|██████████| 188/188 [01:05<00:00,  2.86it/s, loss=0.311]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val Loss: 0.2968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S1 Ep 8: 100%|██████████| 188/188 [01:06<00:00,  2.84it/s, loss=0.291]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val Loss: 0.2571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S1 Ep 9: 100%|██████████| 188/188 [01:05<00:00,  2.88it/s, loss=0.241]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val Loss: 0.2745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S1 Ep 10: 100%|██████████| 188/188 [01:05<00:00,  2.86it/s, loss=0.301]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val Loss: 0.2512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S1 Ep 11: 100%|██████████| 188/188 [01:05<00:00,  2.86it/s, loss=0.423]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val Loss: 0.2606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S1 Ep 12: 100%|██████████| 188/188 [01:06<00:00,  2.84it/s, loss=0.13]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val Loss: 0.2525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S1 Ep 13: 100%|██████████| 188/188 [01:05<00:00,  2.85it/s, loss=0.226]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val Loss: 0.2638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S1 Ep 14: 100%|██████████| 188/188 [01:05<00:00,  2.88it/s, loss=0.291]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val Loss: 0.2802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S1 Ep 15: 100%|██████████| 188/188 [01:06<00:00,  2.85it/s, loss=0.326]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val Loss: 0.2586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S1 Ep 16: 100%|██████████| 188/188 [01:05<00:00,  2.86it/s, loss=0.256]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val Loss: 0.2624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S1 Ep 17: 100%|██████████| 188/188 [01:06<00:00,  2.83it/s, loss=0.123]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val Loss: 0.2527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S1 Ep 18: 100%|██████████| 188/188 [01:05<00:00,  2.87it/s, loss=0.319]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val Loss: 0.2574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S1 Ep 19: 100%|██████████| 188/188 [01:05<00:00,  2.87it/s, loss=0.218]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val Loss: 0.2630\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S1 Ep 20: 100%|██████████| 188/188 [01:05<00:00,  2.87it/s, loss=0.321]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val Loss: 0.2500\n",
            "\n",
            "=== STAGE 2: Unfreezing Backbone (20 Epochs) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S2 Ep 1: 100%|██████████| 188/188 [01:08<00:00,  2.73it/s, loss=0.136]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val MAE: $15.80\n",
            "  >>> New Best Model Saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S2 Ep 2: 100%|██████████| 188/188 [01:05<00:00,  2.89it/s, loss=0.29]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val MAE: $15.83\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S2 Ep 3: 100%|██████████| 188/188 [01:04<00:00,  2.92it/s, loss=0.155]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val MAE: $15.82\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S2 Ep 4: 100%|██████████| 188/188 [01:04<00:00,  2.91it/s, loss=0.242]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val MAE: $15.83\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S2 Ep 5: 100%|██████████| 188/188 [01:05<00:00,  2.86it/s, loss=0.194]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val MAE: $15.79\n",
            "  >>> New Best Model Saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S2 Ep 6: 100%|██████████| 188/188 [01:04<00:00,  2.90it/s, loss=0.207]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val MAE: $15.80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S2 Ep 7: 100%|██████████| 188/188 [01:04<00:00,  2.91it/s, loss=0.203]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val MAE: $15.82\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S2 Ep 8: 100%|██████████| 188/188 [01:05<00:00,  2.87it/s, loss=0.18]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val MAE: $15.77\n",
            "  >>> New Best Model Saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S2 Ep 9: 100%|██████████| 188/188 [01:05<00:00,  2.87it/s, loss=0.198]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val MAE: $15.80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S2 Ep 10: 100%|██████████| 188/188 [01:04<00:00,  2.90it/s, loss=0.174]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val MAE: $15.81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S2 Ep 11: 100%|██████████| 188/188 [01:04<00:00,  2.91it/s, loss=0.193]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val MAE: $15.81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S2 Ep 12: 100%|██████████| 188/188 [01:05<00:00,  2.87it/s, loss=0.243]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val MAE: $15.80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S2 Ep 13: 100%|██████████| 188/188 [01:05<00:00,  2.88it/s, loss=0.17]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val MAE: $15.76\n",
            "  >>> New Best Model Saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S2 Ep 14: 100%|██████████| 188/188 [01:05<00:00,  2.88it/s, loss=0.0891]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val MAE: $15.83\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S2 Ep 15: 100%|██████████| 188/188 [01:05<00:00,  2.88it/s, loss=0.176]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val MAE: $15.85\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S2 Ep 16: 100%|██████████| 188/188 [01:04<00:00,  2.90it/s, loss=0.216]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val MAE: $15.89\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S2 Ep 17: 100%|██████████| 188/188 [01:05<00:00,  2.89it/s, loss=0.221]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val MAE: $15.83\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S2 Ep 18: 100%|██████████| 188/188 [01:04<00:00,  2.89it/s, loss=0.213]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val MAE: $15.84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S2 Ep 19: 100%|██████████| 188/188 [01:04<00:00,  2.91it/s, loss=0.183]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val MAE: $15.81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "S2 Ep 20: 100%|██████████| 188/188 [01:05<00:00,  2.88it/s, loss=0.129]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  >>> Val MAE: $15.81\n",
            "Training Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# This is the path where your script saved the best model\n",
        "model_path = '/content/drive/MyDrive/Classes/AML/asos_final_best.pth'\n",
        "\n",
        "# Check if it exists first\n",
        "if os.path.exists(model_path):\n",
        "    print(f\"Downloading {model_path}...\")\n",
        "    files.download(model_path)\n",
        "else:\n",
        "    print(\"File not found! Check your Drive folder.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WgAaXsUe3lzj",
        "outputId": "599ea5c2-c561-45ca-dfa3-91679cbd9236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading /content/drive/MyDrive/Classes/AML/asos_final_best.pth...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_03a2f5a9-a096-4ba4-b7a1-9e8ddb7745e3\", \"asos_final_best.pth\", 116629191)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2 (Mid-fusion)"
      ],
      "metadata": {
        "id": "jQ-2CuNitp9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import torch.amp\n",
        "import concurrent.futures\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Install additional libraries\n",
        "!pip install -q category_encoders\n",
        "\n",
        "from category_encoders import TargetEncoder\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = 0.0012\n",
        "HIDDEN_DIM = 1024\n",
        "NUM_LAYERS = 2\n",
        "DROPOUT_RATE = 0.3\n",
        "WEIGHT_DECAY = 1e-4\n",
        "\n",
        "# Training Duration\n",
        "EPOCHS_STAGE_1 = 20\n",
        "EPOCHS_STAGE_2 = 20\n",
        "LR_FINE_TUNE = 1e-5\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "SAVE_DIR = '/content/drive/MyDrive/Classes/AML'\n",
        "IMG_DIR = '/content/dataset/asos_images_raw'\n",
        "CLEAN_CSV_PATH = '/content/asos_final_clean.csv'\n",
        "\n",
        "print(f\"Device: {DEVICE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Y1QXMmCju89",
        "outputId": "762ff42d-7dd0-4559-ee91-ede801427499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "df = pd.read_csv(CLEAN_CSV_PATH, on_bad_lines='skip', engine='python')\n",
        "df = df[df['price'] < 1000]\n",
        "\n",
        "# Create train/val/test splits\n",
        "train_val_df, test_df = train_test_split(df, test_size=0.10, random_state=42)\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=0.1111, random_state=42)\n",
        "\n",
        "print(f\"Train: {len(train_df)}\")\n",
        "print(f\"Val:   {len(val_df)}\")\n",
        "print(f\"Test:  {len(test_df)}\")"
      ],
      "metadata": {
        "id": "R9uRnT55D6J-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b1bfe86-c4c2-425d-ef75-590e0960ec56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 23976\n",
            "Val:   2997\n",
            "Test:  2998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_metadata_features(train_df, val_df, test_df):\n",
        "    \"\"\"\n",
        "    Create metadata features aligned with train/val/test splits.\n",
        "    Returns numpy arrays of metadata features.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- 1. TARGET ENCODING (Brand) ---\n",
        "    te = TargetEncoder(cols=['brand'])\n",
        "    train_brand_te = te.fit_transform(train_df['brand'], train_df['price'])\n",
        "    val_brand_te = te.transform(val_df['brand'])\n",
        "    test_brand_te = te.transform(test_df['brand'])\n",
        "\n",
        "    # --- 2. ONE-HOT ENCODING (Low cardinality features) ---\n",
        "    low_cardinality_cols = ['item_category', 'main_material', 'fit_type', 'color_simple']\n",
        "\n",
        "    # Get dummies for each split\n",
        "    train_cats = pd.get_dummies(train_df[low_cardinality_cols], drop_first=False)\n",
        "    val_cats = pd.get_dummies(val_df[low_cardinality_cols], drop_first=False)\n",
        "    test_cats = pd.get_dummies(test_df[low_cardinality_cols], drop_first=False)\n",
        "\n",
        "    # Align columns across all splits\n",
        "    val_cats = val_cats.reindex(columns=train_cats.columns, fill_value=0)\n",
        "    test_cats = test_cats.reindex(columns=train_cats.columns, fill_value=0)\n",
        "\n",
        "    # --- 3. COMBINE FEATURES ---\n",
        "    X_meta_train = pd.concat([train_brand_te, train_cats], axis=1)\n",
        "    X_meta_val = pd.concat([val_brand_te, val_cats], axis=1)\n",
        "    X_meta_test = pd.concat([test_brand_te, test_cats], axis=1)\n",
        "\n",
        "    X_meta_train = X_meta_train.astype(np.float32).values\n",
        "    X_meta_val = X_meta_val.astype(np.float32).values\n",
        "    X_meta_test = X_meta_test.astype(np.float32).values\n",
        "\n",
        "    print(f\"✓ Train metadata shape: {X_meta_train.shape}, dtype: {X_meta_train.dtype}\")\n",
        "    print(f\"✓ Val metadata shape:   {X_meta_val.shape}, dtype: {X_meta_val.dtype}\")\n",
        "    print(f\"✓ Test metadata shape:  {X_meta_test.shape}, dtype: {X_meta_test.dtype}\")\n",
        "\n",
        "    return X_meta_train, X_meta_val, X_meta_test\n",
        "\n",
        "# Generate metadata features\n",
        "X_meta_train, X_meta_val, X_meta_test = prepare_metadata_features(train_df, val_df, test_df)\n",
        "metadata_feature_dim = X_meta_train.shape[1]\n",
        "print(f\"✓ Metadata feature dimension: {metadata_feature_dim}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7It2Ly2lxQt",
        "outputId": "a1b4d9e9-f972-4ba1-f693-f9a081843fd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Train metadata shape: (23976, 97), dtype: float32\n",
            "✓ Val metadata shape:   (2997, 97), dtype: float32\n",
            "✓ Test metadata shape:  (2998, 97), dtype: float32\n",
            "✓ Metadata feature dimension: 97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Image transforms\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "print(\"✓ Transforms defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgdkqCD8eAtm",
        "outputId": "e6036412-7e5b-46b9-ffd5-a17b49e68e7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Transforms defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MidFusionModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Mid-Fusion Architecture:\n",
        "    1. ConvNeXt extracts image features (768-dim)\n",
        "    2. Metadata features are concatenated with image features\n",
        "    3. Combined features pass through fusion head for final prediction\n",
        "    \"\"\"\n",
        "    def __init__(self, metadata_dim, hidden_dim=1024, num_layers=2, dropout_rate=0.3):\n",
        "        super(MidFusionModel, self).__init__()\n",
        "\n",
        "        # Image backbone (ConvNeXt)\n",
        "        self.backbone = models.convnext_tiny(weights='DEFAULT')\n",
        "\n",
        "        # Get the feature dimension from the classifier\n",
        "        self.image_feature_dim = self.backbone.classifier[2].in_features  # 768\n",
        "\n",
        "        # Keep only the feature extraction part (remove classifier)\n",
        "        # ConvNeXt structure: features -> avgpool -> classifier\n",
        "        # We want features + avgpool only\n",
        "        self.backbone.classifier = nn.Identity()\n",
        "\n",
        "        # Add global average pooling to handle the output\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        # Combined dimension: image features + metadata\n",
        "        combined_dim = self.image_feature_dim + metadata_dim\n",
        "\n",
        "        # Fusion Head (Funnel Architecture)\n",
        "        layers = []\n",
        "        current_in = combined_dim\n",
        "\n",
        "        for i in range(num_layers):\n",
        "            out_dim = int(hidden_dim / (2**i))  # 1024 -> 512 -> ...\n",
        "            layers.append(nn.Linear(current_in, out_dim))\n",
        "            layers.append(nn.BatchNorm1d(out_dim))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(dropout_rate))\n",
        "            current_in = out_dim\n",
        "\n",
        "        # Final prediction layer\n",
        "        layers.append(nn.Linear(current_in, 1))\n",
        "\n",
        "        self.fusion_head = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, images, metadata):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            images: (batch_size, 3, 224, 224)\n",
        "            metadata: (batch_size, metadata_dim)\n",
        "        Returns:\n",
        "            predictions: (batch_size, 1)\n",
        "        \"\"\"\n",
        "        # Extract image features through backbone\n",
        "        x = self.backbone.features(images)  # (batch_size, 768, H, W)\n",
        "\n",
        "        # Apply global average pooling\n",
        "        x = self.avgpool(x)  # (batch_size, 768, 1, 1)\n",
        "\n",
        "        # Flatten to get feature vector\n",
        "        image_features = torch.flatten(x, 1)  # (batch_size, 768)\n",
        "\n",
        "        # Concatenate image and metadata features\n",
        "        combined = torch.cat([image_features, metadata], dim=1)\n",
        "\n",
        "        # Pass through fusion head\n",
        "        output = self.fusion_head(combined)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def freeze_backbone(self):\n",
        "        \"\"\"Freeze ConvNeXt backbone for stage 1 training\"\"\"\n",
        "        for param in self.backbone.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def unfreeze_backbone_layers(self, num_blocks=2):\n",
        "        \"\"\"Unfreeze last N blocks of ConvNeXt for fine-tuning\"\"\"\n",
        "        blocks_to_unfreeze = [7, 6, 5, 4][:num_blocks]\n",
        "        for block_idx in blocks_to_unfreeze:\n",
        "            for param in self.backbone.features[block_idx].parameters():\n",
        "                param.requires_grad = True\n",
        "\n",
        "\n",
        "class ASOSMemDatasetWithMeta(Dataset):\n",
        "    \"\"\"Extended dataset that returns images, metadata, and prices\"\"\"\n",
        "    def __init__(self, dataframe, img_dir, metadata_features):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            dataframe: Original dataframe with SKUs and prices\n",
        "            img_dir: Directory containing images\n",
        "            metadata_features: numpy array of metadata features (aligned with dataframe)\n",
        "        \"\"\"\n",
        "        self.metadata_df = dataframe.copy().reset_index(drop=True)\n",
        "        self.img_dir = img_dir\n",
        "        self.metadata_features = metadata_features\n",
        "        self.images = [None] * len(self.metadata_df)\n",
        "        self.prices = [None] * len(self.metadata_df)\n",
        "        self.valid_indices = []\n",
        "\n",
        "        print(f\"Caching {len(self.metadata_df)} images with metadata...\")\n",
        "\n",
        "        def load_single_image(idx):\n",
        "            try:\n",
        "                row = self.metadata_df.iloc[idx]\n",
        "                sku = str(int(row['sku']))\n",
        "                img_path = os.path.join(self.img_dir, f\"{sku}.jpg\")\n",
        "                with Image.open(img_path) as img:\n",
        "                    return idx, img.convert('RGB').resize((224, 224)), float(row['price'])\n",
        "            except:\n",
        "                return idx, None, None\n",
        "\n",
        "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "            futures = [executor.submit(load_single_image, i) for i in range(len(self.metadata_df))]\n",
        "            for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures), unit=\"img\"):\n",
        "                idx, img, price = future.result()\n",
        "                if img is not None:\n",
        "                    self.images[idx] = img\n",
        "                    self.prices[idx] = np.log1p(price)\n",
        "                    self.valid_indices.append(idx)\n",
        "\n",
        "        # Filter to only valid samples\n",
        "        self.images = [self.images[i] for i in self.valid_indices]\n",
        "        self.prices = [self.prices[i] for i in self.valid_indices]\n",
        "        self.metadata_features = self.metadata_features[self.valid_indices]\n",
        "\n",
        "        print(f\"✓ Loaded {len(self.images)} valid samples\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.images[idx]\n",
        "        price = torch.tensor(self.prices[idx], dtype=torch.float32)\n",
        "        metadata = torch.tensor(self.metadata_features[idx], dtype=torch.float32)\n",
        "        return img, metadata, price\n",
        "\n",
        "\n",
        "class TransformedDatasetWithMeta(Dataset):\n",
        "    \"\"\"Wrapper to apply transforms\"\"\"\n",
        "    def __init__(self, base_dataset, transform):\n",
        "        self.base = base_dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.base)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, metadata, price = self.base[idx]\n",
        "        return self.transform(img), metadata, price\n",
        "\n",
        "print(\"✓ Model and dataset classes defined\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bD5ZP-vveB8z",
        "outputId": "cabdd91b-95ea-4121-fe4f-8acbf92ef93f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model and dataset classes defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CREATING DATASETS AND DATALOADERS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Create datasets with metadata\n",
        "train_dataset_fusion = ASOSMemDatasetWithMeta(train_df, IMG_DIR, X_meta_train)\n",
        "val_dataset_fusion = ASOSMemDatasetWithMeta(val_df, IMG_DIR, X_meta_val)\n",
        "test_dataset_fusion = ASOSMemDatasetWithMeta(test_df, IMG_DIR, X_meta_test)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader_fusion = DataLoader(\n",
        "    TransformedDatasetWithMeta(train_dataset_fusion, train_transforms),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_loader_fusion = DataLoader(\n",
        "    TransformedDatasetWithMeta(val_dataset_fusion, val_transforms),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "test_loader_fusion = DataLoader(\n",
        "    TransformedDatasetWithMeta(test_dataset_fusion, val_transforms),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "print(f\"✓ Train batches: {len(train_loader_fusion)}\")\n",
        "print(f\"✓ Val batches:   {len(val_loader_fusion)}\")\n",
        "print(f\"✓ Test batches:  {len(test_loader_fusion)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QryHB-UxeEMK",
        "outputId": "675dfa76-d195-4154-effe-0a75c231b495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "CREATING DATASETS AND DATALOADERS\n",
            "============================================================\n",
            "Caching 23976 images with metadata...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23976/23976 [21:41<00:00, 18.43img/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Loaded 23976 valid samples\n",
            "Caching 2997 images with metadata...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2997/2997 [02:42<00:00, 18.40img/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Loaded 2997 valid samples\n",
            "Caching 2998 images with metadata...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2998/2998 [02:43<00:00, 18.35img/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Loaded 2998 valid samples\n",
            "✓ Train batches: 188\n",
            "✓ Val batches:   24\n",
            "✓ Test batches:  24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BUILDING MID-FUSION MODEL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "fusion_model = MidFusionModel(\n",
        "    metadata_dim=metadata_feature_dim,\n",
        "    hidden_dim=HIDDEN_DIM,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    dropout_rate=DROPOUT_RATE\n",
        ").to(DEVICE)\n",
        "\n",
        "# Freeze backbone for stage 1\n",
        "fusion_model.freeze_backbone()\n",
        "\n",
        "print(f\"✓ Model created\")\n",
        "print(f\"  - Image feature dim: {fusion_model.image_feature_dim}\")\n",
        "print(f\"  - Metadata dim: {metadata_feature_dim}\")\n",
        "print(f\"  - Combined dim: {fusion_model.image_feature_dim + metadata_feature_dim}\")\n",
        "print(f\"  - Backbone frozen: {not next(fusion_model.backbone.parameters()).requires_grad}\")\n",
        "\n",
        "# Setup training\n",
        "criterion = nn.MSELoss()\n",
        "scaler = torch.amp.GradScaler('cuda')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8loTEZk_t1d2",
        "outputId": "a6feffe7-046c-4354-f622-cf3f831440dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "BUILDING MID-FUSION MODEL\n",
            "============================================================\n",
            "✓ Model created\n",
            "  - Image feature dim: 768\n",
            "  - Metadata dim: 97\n",
            "  - Combined dim: 865\n",
            "  - Backbone frozen: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STAGE 1: TRAINING FUSION HEAD (Backbone Frozen)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "optimizer = optim.AdamW(\n",
        "    fusion_model.fusion_head.parameters(),\n",
        "    lr=LEARNING_RATE,\n",
        "    weight_decay=WEIGHT_DECAY\n",
        ")\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
        "\n",
        "for epoch in range(EPOCHS_STAGE_1):\n",
        "    fusion_model.train()\n",
        "    epoch_loss = 0.0\n",
        "    loop = tqdm(train_loader_fusion, desc=f\"Stage 1 Epoch {epoch+1}/{EPOCHS_STAGE_1}\")\n",
        "\n",
        "    for images, metadata, prices in loop:\n",
        "        images = images.to(DEVICE)\n",
        "        metadata = metadata.to(DEVICE)\n",
        "        prices = prices.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            outputs = fusion_model(images, metadata)\n",
        "            loss = criterion(outputs.squeeze(), prices)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    # Validation\n",
        "    fusion_model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, metadata, prices in val_loader_fusion:\n",
        "            images = images.to(DEVICE)\n",
        "            metadata = metadata.to(DEVICE)\n",
        "            prices = prices.to(DEVICE)\n",
        "\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                outputs = fusion_model(images, metadata)\n",
        "                val_loss += criterion(outputs.squeeze(), prices).item()\n",
        "\n",
        "    val_loss /= len(val_loader_fusion)\n",
        "    avg_train_loss = epoch_loss / len(train_loader_fusion)\n",
        "\n",
        "    print(f\"  Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "# Save Stage 1\n",
        "torch.save(fusion_model.state_dict(), os.path.join(SAVE_DIR, 'fusion_stage1.pth'))\n",
        "print(\"✓ Stage 1 checkpoint saved\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DSIHthTt3pw",
        "outputId": "3ec60ab7-df93-4351-bd11-766e664ad858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STAGE 1: TRAINING FUSION HEAD (Backbone Frozen)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 1 Epoch 1/20: 100%|██████████| 188/188 [01:11<00:00,  2.64it/s, loss=0.293]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1: Train Loss = 0.9451, Val Loss = 0.1858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 1 Epoch 2/20: 100%|██████████| 188/188 [01:05<00:00,  2.86it/s, loss=0.499]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2: Train Loss = 0.2475, Val Loss = 0.1970\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 1 Epoch 3/20: 100%|██████████| 188/188 [01:06<00:00,  2.83it/s, loss=0.522]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3: Train Loss = 0.2263, Val Loss = 0.1470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 1 Epoch 4/20: 100%|██████████| 188/188 [01:06<00:00,  2.83it/s, loss=0.21]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4: Train Loss = 0.2069, Val Loss = 0.1391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 1 Epoch 5/20: 100%|██████████| 188/188 [01:06<00:00,  2.83it/s, loss=0.488]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 5: Train Loss = 0.1931, Val Loss = 0.1767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 1 Epoch 6/20: 100%|██████████| 188/188 [01:06<00:00,  2.85it/s, loss=0.216]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 6: Train Loss = 0.1793, Val Loss = 0.1450\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 1 Epoch 7/20: 100%|██████████| 188/188 [01:06<00:00,  2.84it/s, loss=0.221]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 7: Train Loss = 0.1778, Val Loss = 0.1470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 1 Epoch 8/20: 100%|██████████| 188/188 [01:06<00:00,  2.83it/s, loss=0.2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 8: Train Loss = 0.1687, Val Loss = 0.1437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 1 Epoch 9/20: 100%|██████████| 188/188 [01:06<00:00,  2.81it/s, loss=0.195]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 9: Train Loss = 0.1495, Val Loss = 0.1398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 1 Epoch 10/20: 100%|██████████| 188/188 [01:06<00:00,  2.82it/s, loss=0.138]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 10: Train Loss = 0.1458, Val Loss = 0.1369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 1 Epoch 11/20: 100%|██████████| 188/188 [01:06<00:00,  2.82it/s, loss=0.131]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 11: Train Loss = 0.1422, Val Loss = 0.1354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 1 Epoch 12/20: 100%|██████████| 188/188 [01:05<00:00,  2.85it/s, loss=0.174]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 12: Train Loss = 0.1420, Val Loss = 0.1325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 1 Epoch 13/20: 100%|██████████| 188/188 [01:06<00:00,  2.84it/s, loss=0.0874]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 13: Train Loss = 0.1382, Val Loss = 0.1454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 1 Epoch 14/20: 100%|██████████| 188/188 [01:06<00:00,  2.83it/s, loss=0.15]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 14: Train Loss = 0.1370, Val Loss = 0.1234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 1 Epoch 15/20: 100%|██████████| 188/188 [01:06<00:00,  2.83it/s, loss=0.0989]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 15: Train Loss = 0.1362, Val Loss = 0.1370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 1 Epoch 16/20: 100%|██████████| 188/188 [01:06<00:00,  2.82it/s, loss=0.103]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 16: Train Loss = 0.1357, Val Loss = 0.1425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 1 Epoch 17/20: 100%|██████████| 188/188 [01:06<00:00,  2.82it/s, loss=0.182]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 17: Train Loss = 0.1325, Val Loss = 0.1495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 1 Epoch 18/20: 100%|██████████| 188/188 [01:06<00:00,  2.82it/s, loss=0.118]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 18: Train Loss = 0.1296, Val Loss = 0.1261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 1 Epoch 19/20: 100%|██████████| 188/188 [01:06<00:00,  2.83it/s, loss=0.176]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 19: Train Loss = 0.1220, Val Loss = 0.1218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 1 Epoch 20/20: 100%|██████████| 188/188 [01:06<00:00,  2.83it/s, loss=0.126]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 20: Train Loss = 0.1186, Val Loss = 0.1196\n",
            "✓ Stage 1 checkpoint saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STAGE 2: FINE-TUNING (Unfreezing Last 2 Blocks)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "fusion_model.unfreeze_backbone_layers(num_blocks=2)\n",
        "\n",
        "optimizer = optim.AdamW(\n",
        "    fusion_model.parameters(),\n",
        "    lr=LR_FINE_TUNE,\n",
        "    weight_decay=WEIGHT_DECAY\n",
        ")\n",
        "\n",
        "best_mae = float('inf')\n",
        "\n",
        "for epoch in range(EPOCHS_STAGE_2):\n",
        "    fusion_model.train()\n",
        "    epoch_loss = 0.0\n",
        "    loop = tqdm(train_loader_fusion, desc=f\"Stage 2 Epoch {epoch+1}/{EPOCHS_STAGE_2}\")\n",
        "\n",
        "    for images, metadata, prices in loop:\n",
        "        images = images.to(DEVICE)\n",
        "        metadata = metadata.to(DEVICE)\n",
        "        prices = prices.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            outputs = fusion_model(images, metadata)\n",
        "            loss = criterion(outputs.squeeze(), prices)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    # Validation with real dollar MAE\n",
        "    fusion_model.eval()\n",
        "    val_preds = []\n",
        "    val_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, metadata, prices in val_loader_fusion:\n",
        "            images = images.to(DEVICE)\n",
        "            metadata = metadata.to(DEVICE)\n",
        "\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                outputs = fusion_model(images, metadata)\n",
        "\n",
        "            val_preds.extend(outputs.squeeze().float().cpu().numpy())\n",
        "            val_targets.extend(prices.cpu().numpy())\n",
        "\n",
        "    # Convert from log space to dollars\n",
        "    real_preds = np.expm1(np.clip(val_preds, 0, 10))\n",
        "    real_targets = np.expm1(val_targets)\n",
        "    val_mae = np.mean(np.abs(real_preds - real_targets))\n",
        "    avg_train_loss = epoch_loss / len(train_loader_fusion)\n",
        "\n",
        "    print(f\"  Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val MAE = £{val_mae:.2f}\")\n",
        "\n",
        "    if val_mae < best_mae:\n",
        "        best_mae = val_mae\n",
        "        torch.save(fusion_model.state_dict(), os.path.join(SAVE_DIR, 'fusion_best.pth'))\n",
        "        print(f\"  ✓ New best model saved! MAE = £{val_mae:.2f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING COMPLETE!\")\n",
        "print(f\"Best Validation MAE: £{best_mae:.2f}\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJ7TWJSyt5Ce",
        "outputId": "16c0df8e-79f8-4fa1-d5f1-50ef5f051070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STAGE 2: FINE-TUNING (Unfreezing Last 2 Blocks)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 2 Epoch 1/20: 100%|██████████| 188/188 [01:11<00:00,  2.63it/s, loss=0.303]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1: Train Loss = 0.1144, Val MAE = £10.67\n",
            "  ✓ New best model saved! MAE = £10.67\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 2 Epoch 2/20: 100%|██████████| 188/188 [01:08<00:00,  2.76it/s, loss=0.0868]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2: Train Loss = 0.1091, Val MAE = £10.60\n",
            "  ✓ New best model saved! MAE = £10.60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 2 Epoch 3/20: 100%|██████████| 188/188 [01:08<00:00,  2.74it/s, loss=0.181]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3: Train Loss = 0.1085, Val MAE = £10.63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 2 Epoch 4/20: 100%|██████████| 188/188 [01:07<00:00,  2.79it/s, loss=0.126]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4: Train Loss = 0.1078, Val MAE = £10.64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 2 Epoch 5/20: 100%|██████████| 188/188 [01:08<00:00,  2.76it/s, loss=0.26]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 5: Train Loss = 0.1082, Val MAE = £10.65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 2 Epoch 6/20: 100%|██████████| 188/188 [01:07<00:00,  2.78it/s, loss=0.0897]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 6: Train Loss = 0.1046, Val MAE = £10.57\n",
            "  ✓ New best model saved! MAE = £10.57\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 2 Epoch 7/20: 100%|██████████| 188/188 [01:08<00:00,  2.76it/s, loss=0.0813]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 7: Train Loss = 0.1023, Val MAE = £10.64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 2 Epoch 8/20: 100%|██████████| 188/188 [01:08<00:00,  2.76it/s, loss=0.0886]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 8: Train Loss = 0.1029, Val MAE = £10.63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 2 Epoch 9/20: 100%|██████████| 188/188 [01:07<00:00,  2.77it/s, loss=0.151]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 9: Train Loss = 0.1017, Val MAE = £10.64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 2 Epoch 10/20: 100%|██████████| 188/188 [01:07<00:00,  2.77it/s, loss=0.0753]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 10: Train Loss = 0.1009, Val MAE = £10.61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 2 Epoch 11/20: 100%|██████████| 188/188 [01:07<00:00,  2.78it/s, loss=0.0703]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 11: Train Loss = 0.1004, Val MAE = £10.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 2 Epoch 12/20: 100%|██████████| 188/188 [01:07<00:00,  2.78it/s, loss=0.17]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 12: Train Loss = 0.0991, Val MAE = £10.65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 2 Epoch 13/20: 100%|██████████| 188/188 [01:07<00:00,  2.78it/s, loss=0.138]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 13: Train Loss = 0.0980, Val MAE = £10.66\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 2 Epoch 14/20: 100%|██████████| 188/188 [01:08<00:00,  2.76it/s, loss=0.0841]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 14: Train Loss = 0.0960, Val MAE = £10.65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 2 Epoch 15/20: 100%|██████████| 188/188 [01:08<00:00,  2.76it/s, loss=0.0542]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 15: Train Loss = 0.0937, Val MAE = £10.64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 2 Epoch 16/20: 100%|██████████| 188/188 [01:07<00:00,  2.77it/s, loss=0.105]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 16: Train Loss = 0.0946, Val MAE = £10.71\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 2 Epoch 17/20: 100%|██████████| 188/188 [01:07<00:00,  2.78it/s, loss=0.115]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 17: Train Loss = 0.0946, Val MAE = £10.77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 2 Epoch 18/20: 100%|██████████| 188/188 [01:07<00:00,  2.77it/s, loss=0.136]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 18: Train Loss = 0.0935, Val MAE = £10.66\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 2 Epoch 19/20: 100%|██████████| 188/188 [01:07<00:00,  2.77it/s, loss=0.0707]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 19: Train Loss = 0.0921, Val MAE = £10.72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Stage 2 Epoch 20/20: 100%|██████████| 188/188 [01:08<00:00,  2.76it/s, loss=0.0824]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 20: Train Loss = 0.0911, Val MAE = £10.69\n",
            "\n",
            "============================================================\n",
            "TRAINING COMPLETE!\n",
            "Best Validation MAE: £10.57\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EVALUATING ON TEST SET\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load best model\n",
        "fusion_model.load_state_dict(torch.load(os.path.join(SAVE_DIR, 'fusion_best.pth')))\n",
        "fusion_model.eval()\n",
        "\n",
        "test_preds = []\n",
        "test_targets = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, metadata, prices in tqdm(test_loader_fusion, desc=\"Test Inference\"):\n",
        "        images = images.to(DEVICE)\n",
        "        metadata = metadata.to(DEVICE)\n",
        "\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            outputs = fusion_model(images, metadata)\n",
        "\n",
        "        test_preds.extend(outputs.squeeze().float().cpu().numpy())\n",
        "        test_targets.extend(prices.cpu().numpy())\n",
        "\n",
        "# Convert to dollars\n",
        "test_preds_dollar = np.expm1(np.clip(test_preds, 0, 10))\n",
        "test_targets_dollar = np.expm1(test_targets)\n",
        "\n",
        "# Calculate metrics\n",
        "mae = mean_absolute_error(test_targets_dollar, test_preds_dollar)\n",
        "rmse = np.sqrt(mean_squared_error(test_targets_dollar, test_preds_dollar))\n",
        "r2 = r2_score(test_targets_dollar, test_preds_dollar)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL TEST SET RESULTS - MID-FUSION MODEL\")\n",
        "print(\"=\"*60)\n",
        "print(f\"MAE:  £{mae:.2f}\")\n",
        "print(f\"RMSE: £{rmse:.2f}\")\n",
        "print(f\"R²:   {r2:.4f}\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKxiV6x-t6pC",
        "outputId": "dc0ba476-b4cc-4710-96dd-743c620e550c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "EVALUATING ON TEST SET\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Inference: 100%|██████████| 24/24 [00:08<00:00,  2.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "FINAL TEST SET RESULTS - MID-FUSION MODEL\n",
            "============================================================\n",
            "MAE:  £11.03\n",
            "RMSE: £19.88\n",
            "R²:   0.6706\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}